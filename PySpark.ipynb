{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eaa3e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a06907a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.read_csv('test1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "555cdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cda033a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25c93e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.8:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa8cc4154e0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "130d1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1da3b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36687b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e9914c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437d936",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ff673bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv('test1.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cd4612",
   "metadata": {},
   "source": [
    "### Checking the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "59009065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82056624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Adit| 31|        10| 30000|\n",
      "|  Paul| 30|         8| 25000|\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('test1.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c9d5b51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Check the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "13f01f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f0bc3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Adit', age=31, Experience=10, Salary=30000),\n",
       " Row(Name='Paul', age=30, Experience=8, Salary=25000),\n",
       " Row(Name='Alan', age=29, Experience=4, Salary=20000)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13d24284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Adit| 31|        10| 30000|\n",
      "|  Paul| 30|         8| 25000|\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7640839a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|  Name|Experience|\n",
      "+------+----------+\n",
      "|  Adit|        10|\n",
      "|  Paul|         8|\n",
      "|  Alan|         4|\n",
      "|Shakib|         3|\n",
      "|Zubair|         1|\n",
      "|Porter|         2|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0d63aea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c8144e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e67ce8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+-----------------+------------------+\n",
      "|summary|  Name|               age|       Experience|            Salary|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "|  count|     6|                 6|                6|                 6|\n",
      "|   mean|  NULL|26.333333333333332|4.666666666666667|21333.333333333332|\n",
      "| stddev|  NULL| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
      "|    min|  Adit|                21|                1|             15000|\n",
      "|    max|Zubair|                31|               10|             30000|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32a86a",
   "metadata": {},
   "source": [
    "### Adding Columns in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7d6255ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.withColumn('Experience After 2 year',df_pyspark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bbe89027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+-----------------------+\n",
      "|  Name|age|Experience|Salary|Experience After 2 year|\n",
      "+------+---+----------+------+-----------------------+\n",
      "|  Adit| 31|        10| 30000|                     12|\n",
      "|  Paul| 30|         8| 25000|                     10|\n",
      "|  Alan| 29|         4| 20000|                      6|\n",
      "|Shakib| 24|         3| 20000|                      5|\n",
      "|Zubair| 21|         1| 15000|                      3|\n",
      "|Porter| 23|         2| 18000|                      4|\n",
      "+------+---+----------+------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a219a9",
   "metadata": {},
   "source": [
    "### Dropping the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a66fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.drop('Experience After 2 year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "94fcd0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Adit| 31|        10| 30000|\n",
      "|  Paul| 30|         8| 25000|\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbce935",
   "metadata": {},
   "source": [
    "### Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c77e8bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|New Name|age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|    Adit| 31|        10| 30000|\n",
      "|    Paul| 30|         8| 25000|\n",
      "|    Alan| 29|         4| 20000|\n",
      "|  Shakib| 24|         3| 20000|\n",
      "|  Zubair| 21|         1| 15000|\n",
      "|  Porter| 23|         2| 18000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed('Name','New Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cab26f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('test2.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2b138004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5da6a31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Adit|  31|        10| 30000|\n",
      "|  Paul|  30|         8| 25000|\n",
      "|  Alan|  29|         4| 20000|\n",
      "|Shakib|  24|         3| 20000|\n",
      "|Zubair|  21|         1| 15000|\n",
      "|Porter|  23|         2| 18000|\n",
      "| David|NULL|      NULL| 40000|\n",
      "|  NULL|  34|        10| 38000|\n",
      "|  NULL|  36|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f98e97e",
   "metadata": {},
   "source": [
    "### Dropping the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9cd88e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  31|        10| 30000|\n",
      "|  30|         8| 25000|\n",
      "|  29|         4| 20000|\n",
      "|  24|         3| 20000|\n",
      "|  21|         1| 15000|\n",
      "|  23|         2| 18000|\n",
      "|NULL|      NULL| 40000|\n",
      "|  34|        10| 38000|\n",
      "|  36|      NULL|  NULL|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "847421cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Adit|  31|        10| 30000|\n",
      "|  Paul|  30|         8| 25000|\n",
      "|  Alan|  29|         4| 20000|\n",
      "|Shakib|  24|         3| 20000|\n",
      "|Zubair|  21|         1| 15000|\n",
      "|Porter|  23|         2| 18000|\n",
      "| David|NULL|      NULL| 40000|\n",
      "|  NULL|  34|        10| 38000|\n",
      "|  NULL|  36|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1c49c5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Adit| 31|        10| 30000|\n",
      "|  Paul| 30|         8| 25000|\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "db8a6c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Adit| 31|        10| 30000|\n",
      "|  Paul| 30|         8| 25000|\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251daa1b",
   "metadata": {},
   "source": [
    "### Setting threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b54f7007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Adit| 31|        10| 30000|\n",
      "|  Paul| 30|         8| 25000|\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "|  NULL| 34|        10| 38000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how=\"any\",thresh=3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6532e89f",
   "metadata": {},
   "source": [
    "### Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "34375206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Adit| 31|        10| 30000|\n",
      "|  Paul| 30|         8| 25000|\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "|  NULL| 34|        10| 38000|\n",
      "|  NULL| 36|      NULL|  NULL|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how=\"any\",subset=['Age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597eec3e",
   "metadata": {},
   "source": [
    "### Filling the Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7a07ad0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Adit|  31|        10| 30000|\n",
      "|  Paul|  30|         8| 25000|\n",
      "|  Alan|  29|         4| 20000|\n",
      "|Shakib|  24|         3| 20000|\n",
      "|Zubair|  21|         1| 15000|\n",
      "|Porter|  23|         2| 18000|\n",
      "| David|NULL|      NULL| 40000|\n",
      "|  NULL|  34|        10| 38000|\n",
      "|  NULL|  36|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('Missing Values',['Experience','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "60ffcc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Adit|  31|        10| 30000|\n",
      "|  Paul|  30|         8| 25000|\n",
      "|  Alan|  29|         4| 20000|\n",
      "|Shakib|  24|         3| 20000|\n",
      "|Zubair|  21|         1| 15000|\n",
      "|Porter|  23|         2| 18000|\n",
      "| David|NULL|      NULL| 40000|\n",
      "|  NULL|  34|        10| 38000|\n",
      "|  NULL|  36|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8606f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['age', 'Experience', 'Salary'], \n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
    "    ).setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ca68d",
   "metadata": {},
   "source": [
    "# Adding imputation columns to the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eb47dfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Adit|  31|        10| 30000|         31|                10|         30000|\n",
      "|  Paul|  30|         8| 25000|         30|                 8|         25000|\n",
      "|  Alan|  29|         4| 20000|         29|                 4|         20000|\n",
      "|Shakib|  24|         3| 20000|         24|                 3|         20000|\n",
      "|Zubair|  21|         1| 15000|         21|                 1|         15000|\n",
      "|Porter|  23|         2| 18000|         23|                 2|         18000|\n",
      "| David|NULL|      NULL| 40000|         29|                 4|         40000|\n",
      "|  NULL|  34|        10| 38000|         34|                10|         38000|\n",
      "|  NULL|  36|      NULL|  NULL|         36|                 4|         20000|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eb0b2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Adit| 31|        10| 30000|\n",
      "|  Paul| 30|         8| 25000|\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('test1.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2199570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Salary of the people less than or equal to 20000\n",
    "df_pyspark.filter(\"Salary<=20000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "173ffc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|age|\n",
      "+------+---+\n",
      "|  Alan| 29|\n",
      "|Shakib| 24|\n",
      "|Zubair| 21|\n",
      "|Porter| 23|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Salary<=20000\").select(['Name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5feb32f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(df_pyspark['Salary']<=20000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a6d3ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Adit| 31|        10| 30000|\n",
      "|  Paul| 30|         8| 25000|\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['Salary']<=20000) | \n",
    "                  (df_pyspark['Salary']>=15000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e57819e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+\n",
      "|Name|age|Experience|Salary|\n",
      "+----+---+----------+------+\n",
      "|Adit| 31|        10| 30000|\n",
      "|Paul| 30|         8| 25000|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark['Salary']<=20000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0c9dadde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+------+\n",
      "| Name| Departments|salary|\n",
      "+-----+------------+------+\n",
      "| Adit|Data Science| 10000|\n",
      "| Adit|         IOT|  5000|\n",
      "|David|    Big Data|  4000|\n",
      "| Adit|    Big Data|  4000|\n",
      "|David|Data Science|  3000|\n",
      "| Alan|Data Science| 20000|\n",
      "| Alan|         IOT| 10000|\n",
      "| Alan|    Big Data|  5000|\n",
      "|  Bob|Data Science| 10000|\n",
      "|  Bob|    Big Data|  2000|\n",
      "+-----+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('test3.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1e49df8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Departments: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306226e",
   "metadata": {},
   "source": [
    "### Groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c6abacc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "| Name|sum(salary)|\n",
      "+-----+-----------+\n",
      "|  Bob|      12000|\n",
      "| Alan|      35000|\n",
      "| Adit|      19000|\n",
      "|David|       7000|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Grouped to find the maximum salary\n",
    "df_pyspark.groupBy('Name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3432db97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "| Name|       avg(salary)|\n",
      "+-----+------------------+\n",
      "|  Bob|            6000.0|\n",
      "| Alan|11666.666666666666|\n",
      "| Adit| 6333.333333333333|\n",
      "|David|            3500.0|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Name').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "97f2daef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|sum(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      15000|\n",
      "|    Big Data|      15000|\n",
      "|Data Science|      43000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Groupby Departmernts  which gives maximum salary\n",
    "df_pyspark.groupBy('Departments').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0e0f0d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|avg(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|     7500.0|\n",
      "|    Big Data|     3750.0|\n",
      "|Data Science|    10750.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0099c2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| Departments|count|\n",
      "+------------+-----+\n",
      "|         IOT|    2|\n",
      "|    Big Data|    4|\n",
      "|Data Science|    4|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "486a6ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|      73000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f6d9c4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Adit| 31|        10| 30000|\n",
      "|  Paul| 30|         8| 25000|\n",
      "|  Alan| 29|         4| 20000|\n",
      "|Shakib| 24|         3| 20000|\n",
      "|Zubair| 21|         1| 15000|\n",
      "|Porter| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = spark.read.csv('test1.csv',header=True,inferSchema=True)\n",
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "492e759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2bacaf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'age', 'Experience', 'Salary']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f19513d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=[\"age\",\"Experience\"],outputCol=\"Independent Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7f2271d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=featureassembler.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d6df8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+--------------------+\n",
      "|  Name|age|Experience|Salary|Independent Features|\n",
      "+------+---+----------+------+--------------------+\n",
      "|  Adit| 31|        10| 30000|         [31.0,10.0]|\n",
      "|  Paul| 30|         8| 25000|          [30.0,8.0]|\n",
      "|  Alan| 29|         4| 20000|          [29.0,4.0]|\n",
      "|Shakib| 24|         3| 20000|          [24.0,3.0]|\n",
      "|Zubair| 21|         1| 15000|          [21.0,1.0]|\n",
      "|Porter| 23|         2| 18000|          [23.0,2.0]|\n",
      "+------+---+----------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b6cad5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'age', 'Experience', 'Salary', 'Independent Features']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "09da6b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data=output.select(\"Independent Features\",\"Salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1d3853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|Salary|\n",
      "+--------------------+------+\n",
      "|         [31.0,10.0]| 30000|\n",
      "|          [30.0,8.0]| 25000|\n",
      "|          [29.0,4.0]| 20000|\n",
      "|          [24.0,3.0]| 20000|\n",
      "|          [21.0,1.0]| 15000|\n",
      "|          [23.0,2.0]| 18000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "139dd7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/09 13:42:32 WARN Instrumentation: [f67bd394] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "##train test split\n",
    "train_data,test_data=finalized_data.randomSplit([0.75,0.25])\n",
    "regressor=LinearRegression(featuresCol='Independent Features', labelCol='Salary')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f2484d",
   "metadata": {},
   "source": [
    "### Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e35dcb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-263.7076, 1767.624])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b698e039",
   "metadata": {},
   "source": [
    "### Intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c16b2d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19919.060052212404"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f4489",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dcbc02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results=regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "918eb2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------------+\n",
      "|Independent Features|Salary|       prediction|\n",
      "+--------------------+------+-----------------+\n",
      "|          [29.0,4.0]| 20000|19342.03655352618|\n",
      "+--------------------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9b112d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(657.9634464738192, 432915.89689570636)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError,pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8b904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345312cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e3a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb5082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
